{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ai-memes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOK5P/8ybFs8q7M6miPmbPA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/schesa/ai-memes/blob/master/ai_memes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZvnofopnTtR",
        "colab_type": "text"
      },
      "source": [
        "#Check GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAt0RhSynRR5",
        "colab_type": "code",
        "outputId": "ea624e51-5841-4c93-eb14-0ef0bb4926b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "def get_available_gpus():\n",
        "    local_device_protos = device_lib.list_local_devices()\n",
        "    # print(local_device_protos)\n",
        "    return [x.physical_device_desc for x in local_device_protos if x.device_type == 'GPU']\n",
        "get_available_gpus()    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARgLBeh1dQM0",
        "colab_type": "text"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_pdHnRbc3K5",
        "colab_type": "code",
        "outputId": "16b1958c-e9c9-4d60-a4b4-d83058156a9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    print('Note: using Google CoLab')\n",
        "    COLAB = True\n",
        "except:\n",
        "    print('Note: not using Google Colab')\n",
        "    COLAB = False\n",
        "\n",
        "if COLAB:\n",
        "    root_path = \"/content/drive/My Drive/licenta AC/Chesa/data\"\n",
        "else:\n",
        "    root_path = \"./data/captions\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Note: using Google CoLab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYCvXqA7fKAN",
        "colab_type": "text"
      },
      "source": [
        "# Get Dataset\n",
        "* **root_captioning** = \"/content/drive/My Drive/licenta AC/Chesa/data\"\n",
        "* **lookup** -> dict key: Meme id, value list captions containing words & punctuations splitted by space\n",
        "* delete punctuations so that words will be found in Glove\n",
        "* remove non ascii captions\n",
        "* lex -> set of unique words\n",
        "* max_length -> Maximum length of a caption (in words)\n",
        "\n",
        "# Prepare Dataset\n",
        "* split into **train** and **test**\n",
        "* train_images set, train_img list, string path '3001612175_53567ffb58.jpg'\n",
        "* train_descriptions set, add start/stop get from lookup by train_image \n",
        "  ['2092870249_90e3f1855b': ['startseq a ... , ... a jack . endseq'],]\n",
        "* all_train_captions - all merged in list\n",
        "\n",
        "# Build Neural Networks\n",
        "* build **InceptionV3**\n",
        "* encode img features in **train.pkl**\n",
        "* build vocab, cut words with least occurrences\n",
        "* load **glove** embeddings\n",
        "* build embedding matrix for vocab\n",
        "* build **LSTM**\n",
        "\n",
        "# Caption\n",
        "* implement caption prediction beam search\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySzLytJ-0cX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "\n",
        "null_punct = str.maketrans('', '', string.punctuation)\n",
        "\n",
        "def clean_data(list):\n",
        "  for desc in list:\n",
        "    desc = [word.lower() for word in desc.split()]\n",
        "    desc = [w.translate(null_punct) for w in desc]\n",
        "    desc = [word for word in desc if word.isalpha()]\n",
        "    desc = [word for word in desc if len(word)>1]\n",
        "    yield ' '.join(desc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTH_jiizRoCz",
        "colab_type": "code",
        "outputId": "aac749ef-b439-47af-f34d-797157ab6e92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from functools import reduce\n",
        "\n",
        "isascii_word = lambda w: len(w) == len(w.encode())\n",
        "isascii_list = lambda l: reduce(lambda rez, word: rez & True if isascii_word(word) else False & rez, l, True)\n",
        "dirname = os.path.join(root_path, 'ImgFlip500K_Dataset', 'memes')\n",
        "lookup = dict()\n",
        "\n",
        "def print_iterator(it):\n",
        "    for x in it:\n",
        "        print(x, end='\\n')\n",
        "    print('')  # for new line\n",
        "# i = 0\n",
        "for filename in tqdm(os.listdir(dirname)): # foreach json file in memes\n",
        "    # i += 1\n",
        "    # if i < 7:\n",
        "    #   continue\n",
        "    meme_name = Path(filename).stem # remove file extension\n",
        "    with open(os.path.join(dirname, filename)) as json_file:\n",
        "      memes = json.load(json_file)\n",
        "      # lookup[meme_name] = list(map(lambda meme: ' | '.join(meme['boxes']), memes))\n",
        "      lookup[meme_name] = []\n",
        "      for meme in memes:\n",
        "        words = ' | '.join(clean_data(meme['boxes']))\n",
        "        if isascii_list(words):\n",
        "          lookup[meme_name].append(words)\n",
        "    # if i>0:\n",
        "    #   break # TODO REMOVE\n",
        "\n",
        "print(f'Memes loaded: {len(lookup)}') # 99 memes, in the latest dataset 100\n",
        "print(f'Meme example: {lookup[\"Mocking-Spongebob\"][0]}') # when you off the dope | and you think you a bird"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 99/99 [01:04<00:00,  1.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Memes loaded: 99\n",
            "Meme example: when you off the dope | and you think you bird\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWr-qXGaWPC0",
        "colab_type": "code",
        "outputId": "1c118e7c-88d8-4d18-edc9-6dbf3f3a1021",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "max_length = 0\n",
        "lex = set() # set of unique words\n",
        "# for key in lookup:\n",
        "#   [lex.update(d.split()) for d in lookup[key]]\n",
        "#   big_word = reduce(lambda l, rez: len(max(l.split(), key=lambda x: len(x))) if len(max(l.split(), key=lambda x: len(x))) > len(rez) else rez, lookup[key])\n",
        "#   if(len(big_word)> max_length):\n",
        "#     max_length = len(big_word)\n",
        "#     max_word = big_word\n",
        "#   break\n",
        "for desc in lookup:\n",
        "  for word in desc.split():\n",
        "    lex.add(word)\n",
        "    if max_length < len(word):\n",
        "      max_length=max(max_length,len(word))\n",
        "      max_word = word\n",
        "\n",
        "print(f'Unique words: {len(lex)}')\n",
        "print(f'Biggest word: {max_length} chars')\n",
        "max_word\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique words: 99\n",
            "Biggest word: 46 chars\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Bernie-I-Am-Once-Again-Asking-For-Your-Support'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF1-o5GYHq8C",
        "colab_type": "code",
        "outputId": "1dbab5ab-d410-49c2-d561-9f059682a152",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "START = \"startseq\"\n",
        "STOP = \"endseq\"\n",
        "# same as lookup but captions wrapped in Start/Stop\n",
        "train_descriptions = {k:v for k,v in lookup.items()}\n",
        "for n,v in train_descriptions.items(): \n",
        "  for d in range(len(v)):\n",
        "    v[d] = f'{START} {v[d]} {STOP}'\n",
        "max_length += 2 # update maximum caption length\n",
        "print(f'Wrapped captions in Start/Stop')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wrapped captions in Start/Stop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w74A5YweyJey",
        "colab_type": "code",
        "outputId": "c9954a2f-028c-4f49-a89a-0c87865f7fdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "import tensorflow.keras.applications.inception_v3\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "encode_model = InceptionV3(weights='imagenet')\n",
        "encode_model = Model(encode_model.input, encode_model.layers[-2].output)\n",
        "WIDTH = 299\n",
        "HEIGHT = 299\n",
        "OUTPUT_DIM = 2048\n",
        "preprocess_input = tensorflow.keras.applications.inception_v3.preprocess_input\n",
        "\n",
        "print('InceptionV3 loaded!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
            "96116736/96112376 [==============================] - 2s 0us/step\n",
            "InceptionV3 loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4jZwJln0rsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import tensorflow.keras.preprocessing.image\n",
        "import numpy as np\n",
        "\n",
        "def encodeImage(img):\n",
        "  # Resize all images to a standard size (specified bythe image encoding network)\n",
        "  img = img.resize((WIDTH, HEIGHT), Image.ANTIALIAS)\n",
        "  # Convert a PIL image to a numpy array\n",
        "  x = tensorflow.keras.preprocessing.image.img_to_array(img)\n",
        "  # Expand to 2D array\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  # Perform any preprocessing needed by InceptionV3 or others\n",
        "  x = preprocess_input(x)\n",
        "  # Call InceptionV3 (or other) to extract the smaller feature set for the image.\n",
        "  x = encode_model.predict(x) # Get the encoding vector for the image\n",
        "  # Shape to correct form to be accepted by LSTM captioning network.\n",
        "  x = np.reshape(x, OUTPUT_DIM )\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2IxNro5PZgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Nicely formatted time string\n",
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return f\"{h}:{m:>02}:{s:>05.2f}\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1tqKiPpbKZh",
        "colab_type": "code",
        "outputId": "09508470-011b-4d4e-abd6-207b63afb73a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pickle\n",
        "from time import time\n",
        "\n",
        "train_path = os.path.join(root_path,'ImgFlip500K_Dataset',\"data\",f'train{OUTPUT_DIM}.pkl')\n",
        "if not os.path.exists(train_path):\n",
        "  start = time()\n",
        "  encoding_train = {}\n",
        "  train_images_path = os.path.join(root_path,'ImgFlip500K_Dataset','templates','img') \n",
        "  for image_path in tqdm(os.listdir(train_images_path)):\n",
        "    # print(image_path)\n",
        "    img = tensorflow.keras.preprocessing.image.load_img(os.path.join(train_images_path,image_path), target_size=(HEIGHT, WIDTH))\n",
        "    encoding_train[image_path] = encodeImage(img)\n",
        "  with open(train_path, \"wb\") as fp:\n",
        "    pickle.dump(encoding_train, fp)\n",
        "  print(f\"\\nGenerating training set took: {hms_string(time()-start)}\")\n",
        "else:\n",
        "  with open(train_path, \"rb\") as fp:\n",
        "    encoding_train = pickle.load(fp)\n",
        "print('Loaded')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZ-okH4gCVJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_train_captions = []\n",
        "for key, val in train_descriptions.items():\n",
        "    for cap in val:\n",
        "        all_train_captions.append(cap)\n",
        "# print(all_train_captions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlJtUVlnWdtz",
        "colab_type": "text"
      },
      "source": [
        "Words that do not occur very often can be misleading to neural network training.  It is better to simply remove such words.  Here we remove any words that occur less than 10 times.  We display what the total vocabulary shrunk to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CauyczOdWgEH",
        "colab_type": "code",
        "outputId": "964516ee-9428-4817-fc32-214cffeb953e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word_count_threshold = 1\n",
        "word_counts = {}\n",
        "nsents = 0 # number of sentences\n",
        "for sent in all_train_captions:\n",
        "    nsents += 1\n",
        "    for w in sent.split(' '):\n",
        "        word_counts[w] = word_counts.get(w, 0) + 1\n",
        "\n",
        "vocab = [w for w in word_counts if word_counts[w] >= word_count_threshold]\n",
        "print('preprocessed words %d ==> %d' % (len(word_counts), len(vocab)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "preprocessed words 127547 ==> 127547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSIyQkwufP16",
        "colab_type": "text"
      },
      "source": [
        "Next we build two lookup tables for this vocabulary. One idxtoword convers index numbers to actual words to index values.  The wordtoidx lookup table performs the opposit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CXsUoeUfcfI",
        "colab_type": "code",
        "outputId": "ff194bc2-3d52-49d9-aa70-52380e4bd365",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "idxtoword = {}\n",
        "wordtoidx = {}\n",
        "\n",
        "ix = 1\n",
        "for w in vocab:\n",
        "    wordtoidx[w] = ix\n",
        "    idxtoword[ix] = w\n",
        "    ix += 1\n",
        "    \n",
        "vocab_size = len(idxtoword) + 1 \n",
        "vocab_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "127548"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHYGHAnsul0S",
        "colab_type": "text"
      },
      "source": [
        " # Loading Glove Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IY_9XZ4Hec73",
        "outputId": "8fbcad8e-3673-48ff-e34e-de2de23a6d96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "glove_dir = os.path.join(root_path,'glove.6B')\n",
        "embeddings_index = {} \n",
        "f = open(os.path.join(glove_dir, 'glove.6B.200d.txt'), encoding=\"utf-8\")\n",
        "\n",
        "for line in tqdm(f):\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "\n",
        "f.close()\n",
        "print(f'Found {len(embeddings_index)} word vectors.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400000it [00:23, 16855.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iQbZYXmwSle",
        "colab_type": "text"
      },
      "source": [
        "An embedding matrix is built from Glove.  This will be directly copied to the weight matrix of the neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcIsVlMkwTLq",
        "colab_type": "code",
        "outputId": "bf1a943f-8e34-461c-e63e-066ec1892fc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embedding_dim = 200\n",
        "\n",
        "# Get 200-dim dense vector for each of the 10000 words in out vocabulary\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "not_found = []\n",
        "for word, i in wordtoidx.items():\n",
        "    #if i < max_words:\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in the embedding index will be all zeros\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else: \n",
        "      not_found.append(word)\n",
        "print(f'Not founded words: {len(not_found)} from total of {len(wordtoidx)}')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Not founded words: 67437 from total of 127547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31MvYFI2APGM",
        "colab_type": "text"
      },
      "source": [
        "Clean captions that contain not founded words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-efTGYF389He",
        "colab_type": "code",
        "outputId": "557c0da6-0b22-4dc5-e664-9ba991b5f998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "eliminated = 0\n",
        "def hasNotFoundWord(desc):\n",
        "  global eliminated\n",
        "  stripped_desc = desc.split()[1:-1]\n",
        "  if bool(set(not_found) & set(stripped_desc)):\n",
        "    eliminated += 1\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "train_desc_path = os.path.join(root_path,'ImgFlip500K_Dataset',\"data\",f'{train_descriptions}.pkl')\n",
        "if not os.path.exists(train_desc_path):\n",
        "  for meme in tqdm(train_descriptions):\n",
        "    train_descriptions[meme] = [desc for desc in train_descriptions[meme] if hasNotFoundWord(desc) == False ]\n",
        "    # train_descriptions[meme] = [desc for desc in train_descriptions[meme] if all(unknown not in desc.split()[1:-1] for unknown in not_found)]\n",
        "  # with open(train_desc_path, \"wb\") as fp:\n",
        "  #   pickle.dump(train_descriptions, fp)\n",
        "  print(f\"\\nGenerated Training Descriptions\")\n",
        "else:\n",
        "  with open(train_desc_path, \"rb\") as fp:\n",
        "    train_descriptions = pickle.load(fp)\n",
        "  print(f\"\\n Loaded\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 99/99 [29:00<00:00, 17.58s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Generated Training Descriptions\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtav0xnlWRzk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(f\"\\nGenerated Training Descriptions\")\n",
        "all_train_captions = []\n",
        "for key, val in train_descriptions.items():\n",
        "    for cap in val:\n",
        "        all_train_captions.append(cap)\n",
        "# print(f'Removed captions: {eliminated} from total of {len(all_train_captions)}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJnpcxuEwVSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Embedding, TimeDistributed, Dense, RepeatVector,\\\n",
        "                         Activation, Flatten, Reshape, concatenate, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras import Input, layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import add\n",
        "\n",
        "inputs1 = Input(shape=(OUTPUT_DIM,))\n",
        "fe1 = Dropout(0.5)(inputs1)\n",
        "fe2 = Dense(256, activation='relu')(fe1)\n",
        "inputs2 = Input(shape=(max_length,))\n",
        "se1 = Embedding(vocab_size, embedding_dim, mask_zero=True)(inputs2)\n",
        "se2 = Dropout(0.5)(se1)\n",
        "se3 = LSTM(256)(se2)\n",
        "decoder1 = add([fe2,se3])\n",
        "decoder2 = Dense(256, activation='relu')(decoder1)\n",
        "outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
        "caption_model = Model(inputs=[inputs1,inputs2], outputs=outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW8l1Nq-6Kn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# caption_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DuEo9jV6mpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "caption_model.layers[2].set_weights([embedding_matrix])\n",
        "caption_model.layers[2].trainable = False\n",
        "\n",
        "caption_model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym3IISvU6_s6",
        "colab_type": "text"
      },
      "source": [
        "# Train Nework"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IaG8UqU76u2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def data_generator(descriptions, photos, wordtoidx, max_length, num_photos_per_batch, num_descriptions_per_batch):\n",
        "  # x1 - Training data for photos\n",
        "  # x2 - The caption that goes with each photo\n",
        "  # y - The predicted rest of the caption\n",
        "  x1, x2, y = [], [], []\n",
        "  n=0\n",
        "  while True:\n",
        "    for key, desc_list in descriptions.items():\n",
        "      n+=1\n",
        "      # print(key+'.jpg')\n",
        "      photo = photos[key+'.jpg']\n",
        "      d=0\n",
        "      # Each photo has 5 descriptions\n",
        "      for desc in desc_list:\n",
        "        d+=1\n",
        "        if d==num_descriptions_per_batch:\n",
        "          yield ([np.array(x1), np.array(x2)], np.array(y))\n",
        "          x1, x2, y = [], [], []\n",
        "          d=0\n",
        "        # Convert each word into a list of sequences.\n",
        "        seq = [wordtoidx[word] for word in desc.split(' ') if word in wordtoidx]\n",
        "        # Generate a training case for every possible sequence and outcome\n",
        "        for i in range(1, len(seq)):\n",
        "          in_seq, out_seq = seq[:i], seq[i]\n",
        "          in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "          out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "          x1.append(photo)\n",
        "          x2.append(in_seq)\n",
        "          y.append(out_seq)\n",
        "      # if n==num_photos_per_batch:\n",
        "      #   yield ([np.array(x1), np.array(x2)], np.array(y))\n",
        "      #   x1, x2, y = [], [], []\n",
        "      #   n=0\n",
        "    # break  # TODO REMOVE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SOaVMwE78am",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EPOCHS = 1\n",
        "# model_path = os.path.join(root_path,'ImgFlip500K_Dataset',\"data\",f'caption-model.hdf5')\n",
        "# if not os.path.exists(model_path):\n",
        "#   for i in tqdm(range(EPOCHS*2)):\n",
        "#       generator = data_generator(train_descriptions, encoding_train, wordtoidx, max_length, number_pics_per_bath)\n",
        "#       caption_model.fit(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n",
        "\n",
        "#   caption_model.optimizer.lr = 1e-4\n",
        "#   number_pics_per_bath = 6\n",
        "#   steps = len(train_descriptions)//number_pics_per_bath\n",
        "\n",
        "#   for i in range(EPOCHS):\n",
        "#       generator = data_generator(train_descriptions, encoding_train, wordtoidx, max_length, number_pics_per_bath)\n",
        "#       caption_model.fit(generator, epochs=1, steps_per_epoch=steps, verbose=1)  \n",
        "#   caption_model.save_weights(model_path)\n",
        "#   print(f\"\\Training took: {hms_string(time()-start)}\")\n",
        "# else:\n",
        "#   caption_model.load_weights(model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fme5HwhBeXW",
        "colab_type": "code",
        "outputId": "db6e0bec-4885-458e-eed3-7e92ba9a9493",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "number_pics_per_bath = 1\n",
        "\n",
        "EPOCHS = 10\n",
        "#steps = 1 # TODO REMOVE\n",
        "start = time()\n",
        "num_descriptions_per_batch=30\n",
        "steps = (len(all_train_captions))//num_descriptions_per_batch-1\n",
        "print(f'steps: {steps}')\n",
        "model_path = os.path.join(root_path,'ImgFlip500K_Dataset',\"data\",'caption-model.hdf5')\n",
        "if not os.path.exists(model_path):\n",
        "  # for i in tqdm(range(EPOCHS)):\n",
        "  #   print(f'i: {i}')\n",
        "  generator = data_generator(train_descriptions, encoding_train, wordtoidx, max_length, number_pics_per_bath, num_descriptions_per_batch)\n",
        "  print(f'\\n Fitting Steps1 {steps}\\n')\n",
        "  caption_model.fit(generator, epochs=EPOCHS, steps_per_epoch=steps, verbose=1)\n",
        "  print(f'\\n Done fitting\\n')\n",
        "\n",
        "  caption_model.optimizer.lr = 1e-4\n",
        "  # number_pics_per_bath = 6\n",
        "  # steps = len(train_descriptions)//number_pics_per_bath\n",
        "  #steps=1\n",
        "\n",
        "        # num_descriptions_per_batch=50\n",
        "        # EPOCHS = 30\n",
        "        # steps = (len(all_train_captions))//num_descriptions_per_batch-1\n",
        "        # generator = data_generator(train_descriptions, encoding_train, wordtoidx, max_length, number_pics_per_bath, num_descriptions_per_batch)\n",
        "        # print(f'\\n Fitting Steps1 {steps}\\n')\n",
        "        # caption_model.fit(generator, epochs=EPOCHS, steps_per_epoch=steps, verbose=2)\n",
        "\n",
        "  # steps = len(all_train_captions)//num_descriptions_per_batch\n",
        "  # for i in tqdm(range(EPOCHS)):\n",
        "  #     generator = data_generator(train_descriptions, encoding_train, wordtoidx, max_length, number_pics_per_bath, num_descriptions_per_batch)\n",
        "  #     print(f'\\n Steps2 {steps}\\n')\n",
        "  #     caption_model.fit(generator, epochs=1, steps_per_epoch=steps, verbose=1)  \n",
        "  caption_model.save_weights(model_path)\n",
        "  print(f\"\\Training took: {hms_string(time()-start)}\")\n",
        "else:\n",
        "  caption_model.load_weights(model_path)\n",
        "  print('Model loaded')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "steps: 15070\n",
            "\n",
            " Fitting Steps1 15070\n",
            "\n",
            "Epoch 1/10\n",
            "15070/15070 [==============================] - 4025s 267ms/step - loss: 5.3889\n",
            "Epoch 2/10\n",
            " 1197/15070 [=>............................] - ETA: 1:02:16 - loss: 5.0784"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quNSodPQrCYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generateCaption(photo):\n",
        "    in_text = START\n",
        "    for i in range(max_length):\n",
        "        sequence = [wordtoidx[w] for w in in_text.split() if w in wordtoidx]\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        yhat = caption_model.predict([photo,sequence], verbose=0)\n",
        "        yhat = np.argmax(yhat)\n",
        "        word = idxtoword[yhat]\n",
        "        in_text += ' ' + word\n",
        "        print(word)\n",
        "        if word == STOP:\n",
        "            break\n",
        "    final = in_text.split()\n",
        "    final = final[1:-1]\n",
        "    final = ' '.join(final)\n",
        "    return final"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NQnC5c3rHAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  #img = 'Mocking-Spongebob.jpg'\n",
        "  #img = 'I-Should-Buy-A-Boat-Cat.jpg'\n",
        "  for img in train_descriptions.keys():\n",
        "    image = encoding_train[f'{img}.jpg'].reshape((1,OUTPUT_DIM))\n",
        "    x = plt.imread(os.path.join(root_path,'ImgFlip500K_Dataset','templates','img', f'{img}.jpg'))\n",
        "    plt.imshow(x)\n",
        "    plt.show()\n",
        "    print(image)\n",
        "    print(\"Caption:\",generateCaption(image))\n",
        "    print(\"_____________________________________\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrSk36zfsUlg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(all_train_captions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk2X7BHUjRuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def beam_search_predictions(image, beam_index = 3):\n",
        "    start = [wordtoidx[START]]\n",
        "    \n",
        "    # start_word[0][0] = index of the starting word\n",
        "    # start_word[0][1] = probability of the word predicted\n",
        "    start_word = [[start, 0.0]]\n",
        "    \n",
        "    while len(start_word[0][0]) < max_length:\n",
        "        temp = []\n",
        "        for s in start_word:\n",
        "            par_caps = pad_sequences([s[0]], maxlen=max_length, padding='post')\n",
        "            e = encoding_train[image]\n",
        "            preds = caption_model.predict([np.array([e]), np.array(par_caps)])\n",
        "            \n",
        "            # Getting the top <beam_index>(n) predictions\n",
        "            word_preds = np.argsort(preds[0])[-beam_index:]\n",
        "            \n",
        "            # creating a new list so as to put them via the model again\n",
        "            for w in word_preds:\n",
        "                # print('w')\n",
        "                # print(idxtoword[w])\n",
        "                next_cap, prob = s[0][:], s[1]\n",
        "                next_cap.append(w)\n",
        "                prob += preds[0][w]\n",
        "                temp.append([next_cap, prob])\n",
        "                    \n",
        "        start_word = temp\n",
        "        print(temp)\n",
        "        # Sorting according to the probabilities\n",
        "        start_word = sorted(start_word, reverse=False, key=lambda l: l[1])\n",
        "        # Getting the top words\n",
        "        start_word = start_word[-beam_index:]\n",
        "    print('start_word')\n",
        "    for caption in start_word[-1]:\n",
        "      print([idxtoword[i] for i in caption])\n",
        "    print(start_word)\n",
        "    start_word = start_word[-1][0]\n",
        "    intermediate_caption = [idxtoword[i] for i in start_word]\n",
        "    print(intermediate_caption)\n",
        "    final_caption = []\n",
        "    \n",
        "    for i in intermediate_caption:\n",
        "        if i != STOP:\n",
        "            final_caption.append(i)\n",
        "        else:\n",
        "            break\n",
        "    \n",
        "    final_caption = ' '.join(final_caption[1:])\n",
        "    return final_caption"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo5f5KX9lpc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for img in train_descriptions.keys():\n",
        "#   img =  f'{img}.jpg'\n",
        "#   print(beam_search_predictions(img, 7))\n",
        "#   x = plt.imread(os.path.join(root_path,'ImgFlip500K_Dataset','templates','img',img))\n",
        "#   plt.imshow(x)\n",
        "#   plt.show()\n",
        "#   print(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02L8uuP06GIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    img = 'I-Should-Buy-A-Boat-Cat.jpg'\n",
        "    photo = encoding_train[img].reshape((1,OUTPUT_DIM))\n",
        "    in_text = START\n",
        "    # for i in range(max_length):\n",
        "    sequence = [wordtoidx[w] for w in in_text.split() if w in wordtoidx]\n",
        "    sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "    yhat = caption_model.predict([photo,sequence], verbose=0)\n",
        "    idxtoword[0]='0'\n",
        "    # np.where(yhat[0] == yhat[0][2])[0][0]    \n",
        "    probab = [[np.where(yhat[0] == p)[0][0], p] for p in list(yhat[0])]\n",
        "    probab = [ [idxtoword[x[0]],x[1]] for x in probab if x[1]>0.01]\n",
        "    probab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNJ452kxqQOj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def beam_search(img, beam_index = 3):\n",
        "  start = [wordtoidx[START]]\n",
        "  start_word = [[start, 0.0]]\n",
        "\n",
        "  while len(start_word[0][0]) < max_length:\n",
        "\n",
        "    temp = []\n",
        "    for s in start_word:\n",
        "\n",
        "      par_caps = pad_sequences([s[0]], maxlen=max_length, padding='post')\n",
        "      e = encoding_train[img]\n",
        "      preds = caption_model.predict([np.array([e]), np.array(par_caps)])\n",
        "\n",
        "      word_preds = np.argsort(preds[0])[-beam_index:]\n",
        "      # print(word_preds)\n",
        "      # creating a new list so as to put them via the model again\n",
        "      for w in word_preds:\n",
        "          # print(w)\n",
        "          # print(idxtoword(w[0]))\n",
        "          next_cap, prob = s[0][:], s[1]\n",
        "          # print(next_cap)\n",
        "          # print(idxtoword[next_cap[0]])\n",
        "          next_cap.append(w)\n",
        "          prob += preds[0][w]\n",
        "          temp.append([next_cap, prob])\n",
        "                              \n",
        "          start_word = temp\n",
        "          # print(temp)\n",
        "          # Sorting according to the probabilities\n",
        "          start_word = sorted(start_word, reverse=False, key=lambda l: l[1])\n",
        "          # Getting the top words\n",
        "          start_word = start_word[-beam_index:]\n",
        "          \n",
        "  # print('start_word')\n",
        "  # print(start_word)\n",
        "  l = []\n",
        "  for rez in start_word:\n",
        "     l.append([[idxtoword[i] for i in rez[0]],rez[1]])\n",
        "  return l\n",
        "\n",
        "    # print([[idxtoword[i] for i in caption[0]],caption[1]])\n",
        "  # start_word = start_word[-1][0]\n",
        "  # intermediate_caption = [idxtoword[i] for i in start_word]\n",
        "  # print(intermediate_caption)\n",
        "  # final_caption = []\n",
        "\n",
        "  # for i in intermediate_caption:\n",
        "  #     if i != STOP:\n",
        "  #         final_caption.append(i)\n",
        "  #     else:\n",
        "  #         break\n",
        "\n",
        "  # final_caption = ' '.join(final_caption[1:])\n",
        "  # print(final_caption)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6LB6Z4Rveee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for img in train_descriptions.keys():\n",
        "  img =  f'{img}.jpg'\n",
        "  x = plt.imread(os.path.join(root_path,'ImgFlip500K_Dataset','templates','img',img))\n",
        "  plt.imshow(x)\n",
        "  plt.show()\n",
        "  print(img)\n",
        "  for caption in beam_search(img, 30):\n",
        "    print(caption[0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JtlLlUCidX4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def diff_beam_search(img, beam_index = 3):\n",
        "  start = [wordtoidx[START]]\n",
        "  start_word = [[start, 0.0]]\n",
        "  first = True\n",
        "  while len(start_word[0][0]) < max_length:\n",
        "\n",
        "    temp = []\n",
        "    for s in start_word:\n",
        "\n",
        "      par_caps = pad_sequences([s[0]], maxlen=max_length, padding='post')\n",
        "      preds = caption_model.predict([np.array([img]), np.array(par_caps)])\n",
        "\n",
        "      # if first == True:\n",
        "      #   np.random.shuffle(preds)\n",
        "      #   word_preds = preds[0][-beam_index:]\n",
        "      # else:\n",
        "      word_preds = np.argsort(preds[0])[-beam_index:]\n",
        "      # print(word_preds)\n",
        "      # creating a new list so as to put them via the model again\n",
        "      for w in word_preds:\n",
        "          # print(w)\n",
        "          # print(idxtoword(w[0]))\n",
        "          next_cap, prob = s[0][:], s[1]\n",
        "          # print(next_cap)\n",
        "          # print(idxtoword[next_cap[0]])\n",
        "          next_cap.append(w)\n",
        "          prob += preds[0][w]\n",
        "          temp.append([next_cap, prob])\n",
        "                              \n",
        "          start_word = temp\n",
        "          # print(temp)\n",
        "          # Sorting according to the probabilities\n",
        "          start_word = sorted(start_word, reverse=False, key=lambda l: l[1])\n",
        "          # Getting the top words\n",
        "          start_word = start_word[-beam_index:]\n",
        "  # print('start_word')\n",
        "  # print(start_word)\n",
        "  l = []\n",
        "  for rez in start_word:\n",
        "     l.append([[idxtoword[i] for i in rez[0]],rez[1]])\n",
        "  return l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "firEllw2jKbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for img in train_descriptions.keys():\n",
        "  img = tensorflow.keras.preprocessing.image.load_img(os.path.join(root_path,'custom_images','WIN_20190821_08_34_54_Pro.jpg'), target_size=(HEIGHT, WIDTH))\n",
        "  x = plt.imread(os.path.join(root_path,'custom_images','WIN_20190821_08_34_54_Pro.jpg'))\n",
        "  plt.imshow(x)\n",
        "  plt.show()\n",
        "  print(img)\n",
        "  for caption in diff_beam_search(encodeImage(img), 6):\n",
        "    print(caption[0])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}